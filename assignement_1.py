# -*- coding: utf-8 -*-
"""Assignement-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MZaIs14pn-55wTjX59VF3R3o1DyV_0MM
"""

import spacy
spacy_nlp = spacy.load('en_core_web_sm')
input_sentence = 'I saw the man with a telescope'


#EX1
def get_dependency_path(doc):
    for token in doc:
        list = []
        list.append(token.dep_ + ' : ' + token.lower_)
     
        for tmp in token.ancestors:
            list.append(tmp.dep_ + ' : ' + tmp.lower_)
        list.reverse()
        print(token.lower_ + ' : ' + str(list))


#EX2

def get_dependencies_tree(doc):
    for token in doc:
        print('Dependencies subtree for token "{0}" is:'.format(token.lower_))
        list = []
        for tmp in token.subtree:
            list.append(tmp.lower_)
        print(list)
        try:
            to_nltk_tree(token).pretty_print()
        except AttributeError:
            print(token)


#EX3

def is_subtree(input_sentence, test_snt):

    #parsing
    sent = spacy_nlp(input_sentence)
    test = spacy_nlp(test_snt)

    #funct:
    subtree = []
    test_txt = [token.text for token in test]
    print("Testing: {}".format(test_txt))
    
    #return subtree only:
    for token1 in test:
        for token in sent:
            if token.text == token1.text:
                subtree = token.subtree
                sbt_txt = [toks.text for toks in subtree]
                #print(sbt_txt)

                if (test_txt == sbt_txt):
                    print("Found subtree: {}".format(sbt_txt))
                    return True
    
    print("Not a subtree.")
    return False

#EX4

def headOfSpan(input_sentence):
    doc = nlp(input_sentence)
    span = doc[:]
    print("span: ", span)
    return span.root  

#EX5
def get_spans(input_sentence):
    doc=spacy_nlp(input_sentence)
    spans_dict=dict()
    for token in doc:
        if token.dep_=='nsubj' or token.dep_=="dobj" or token.dep_=="dative":
            span=doc[token.left_edge.i:token.right_edge.i+1]
            span_list=[]
            for i in span:
                span_list.append(i)
            spans_dict[(token,token.dep_)]=span_list
    return spans_dict

def main():

    print('Exercise sentence:')
    print(input_sentence)
    document = spacy_nlp(input_sentence)

    print()

    # EXERCISE_1
    print('1) Printing EX1 results...')
    print()
    get_dependency_path(document)

    print()

    # EXERCISE_2
    print('2) Printing EX2 results...')
    print()
    get_dependencies_tree(document)

    print()

    # EXERCISE_3
    print('3) Printing EX3 results...')
    print()

    sample_1 = 'a telescope'
    sample_2 = 'saw the'
    sample_3 = 'the man'
    print(is_subtree(input_sentence, sample_1)) 
    print(is_subtree(input_sentence, sample_2)) 
    print(is_subtree(input_sentence, sample_3)) 

    print()

    # EXERCISE_4
    print('4) Printing EX4 results...')
    print()
    span = "the man with"
    print("head of span: ", headOfSpan(span))
    print()

    print()

    # EXERCISE_5
    print('5) Printing EX5 results...')
    print()
    print(get_spans(input_sentence))

main()